{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Structure Evaluation – PyTorch MLP\n",
    "\n",
    "This notebook trains a regression model that predicts the similarity score (0–1) for a generated table JSON vs ground truth.\n",
    "\n",
    "- Dataset: `rayhu/table-extraction-evaluation` ([Hugging Face dataset](https://huggingface.co/datasets/rayhu/table-extraction-evaluation))\n",
    "- Model: PyTorch MLP\n",
    "- Representation modes:\n",
    "  - structured: numeric features from JSON structure\n",
    "  - embed: optional lightweight text embedding via averaging token vectors (HF backbone not required for baseline)\n",
    "  - hybrid: concatenate structured + embed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rayhu/play/ai/cs230-evaluation-model/.venv/bin/python3.13\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "SEED = 42\n",
    "VAL_FRAC = 0.5  # fraction of the original test split to use as validation (rest is test)\n",
    "LIMIT = None     # e.g., 2000 for quick smoke tests, or None for full\n",
    "REPRESENTATION_MODE = \"structured\"  # \"structured\" | \"embed\" | \"hybrid\"\n",
    "\n",
    "# MLP defaults\n",
    "HIDDEN_SIZES = [256, 256]\n",
    "DROPOUT = 0.1\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "SEED = 42\n",
    "VAL_FRAC = 0.5  # fraction of the original test split to use as validation (rest is test)\n",
    "LIMIT = None     # e.g., 2000 for quick smoke tests, or None for full\n",
    "REPRESENTATION_MODE = \"structured\"  # \"structured\" | \"embed\" | \"hybrid\"\n",
    "\n",
    "# MLP defaults\n",
    "HIDDEN_SIZES = [256, 256]\n",
    "DROPOUT = 0.1\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-3\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from datasets import load_dataset\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 11971 val: 1500 test: 1500\n"
     ]
    }
   ],
   "source": [
    "# Data loading and split from Hugging Face\n",
    "\n",
    "ds = load_dataset(\"rayhu/table-extraction-evaluation\")\n",
    "train_ds = ds[\"train\"]\n",
    "# Split original test into val/test\n",
    "split = train_test = ds[\"test\"].train_test_split(test_size=1-VAL_FRAC, seed=SEED)\n",
    "val_ds = split[\"train\"]\n",
    "test_ds = split[\"test\"]\n",
    "\n",
    "# Optional LIMIT for quick runs\n",
    "if LIMIT is not None:\n",
    "    train_ds = train_ds.select(range(min(LIMIT, len(train_ds))))\n",
    "    val_ds = val_ds.select(range(min(max(1, LIMIT//5), len(val_ds))))\n",
    "    test_ds = test_ds.select(range(min(max(1, LIMIT//5), len(test_ds))))\n",
    "\n",
    "print(\"train:\", len(train_ds), \"val:\", len(val_ds), \"test:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "\n",
    "def table_dims(cells: List[Dict[str, Any]]) -> Tuple[int, int]:\n",
    "    if not cells:\n",
    "        return 0, 0\n",
    "    max_row = 0\n",
    "    max_col = 0\n",
    "    for c in cells:\n",
    "        max_row = max(max_row, int(c.get(\"end_row\", 0)))\n",
    "        max_col = max(max_col, int(c.get(\"end_col\", 0)))\n",
    "    return max_row + 1, max_col + 1\n",
    "\n",
    "\n",
    "def table_stats(cells: List[Dict[str, Any]]) -> Dict[str, float]:\n",
    "    rows, cols = table_dims(cells)\n",
    "    num_cells = len(cells)\n",
    "    spans = []\n",
    "    for c in cells:\n",
    "        r = int(c.get(\"end_row\", 0)) - int(c.get(\"start_row\", 0)) + 1\n",
    "        cc = int(c.get(\"end_col\", 0)) - int(c.get(\"start_col\", 0)) + 1\n",
    "        spans.append(r * cc)\n",
    "    avg_span = float(np.mean(spans)) if spans else 0.0\n",
    "    max_span = float(np.max(spans)) if spans else 0.0\n",
    "    return {\n",
    "        \"rows\": rows,\n",
    "        \"cols\": cols,\n",
    "        \"num_cells\": float(num_cells),\n",
    "        \"avg_span\": avg_span,\n",
    "        \"max_span\": max_span,\n",
    "    }\n",
    "\n",
    "\n",
    "def build_structured_features(example: Dict[str, Any]) -> Tuple[np.ndarray, List[str]]:\n",
    "    gt_cells = example[\"ground_truth\"][\"cells\"]\n",
    "    gen_cells = example[\"generated\"][\"cells\"]\n",
    "    gt = table_stats(gt_cells)\n",
    "    pr = table_stats(gen_cells)\n",
    "    feats = {}\n",
    "    for k in [\"rows\", \"cols\", \"num_cells\", \"avg_span\", \"max_span\"]:\n",
    "        feats[f\"gt_{k}\"] = gt[k]\n",
    "        feats[f\"pred_{k}\"] = pr[k]\n",
    "        feats[f\"delta_{k}\"] = pr[k] - gt[k]\n",
    "        feats[f\"ratio_{k}\"] = (pr[k] / gt[k]) if gt[k] not in (0, 0.0) else 0.0\n",
    "    names = list(feats.keys())\n",
    "    return np.array([feats[k] for k in names], dtype=np.float32), names\n",
    "\n",
    "\n",
    "def render_structure_string(cells: List[Dict[str, Any]], include_text: bool = True) -> str:\n",
    "    parts = []\n",
    "    for c in cells:\n",
    "        pos = f\"r{c.get('start_row',0)}c{c.get('start_col',0)}-r{c.get('end_row',0)}c{c.get('end_col',0)}\"\n",
    "        if include_text:\n",
    "            content = \" \".join(c.get(\"content\", [])[:5])  # cap for length\n",
    "            parts.append(f\"{pos}:{content}\")\n",
    "        else:\n",
    "            parts.append(pos)\n",
    "    return \" | \".join(parts[:512])  # truncate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11971, 20), (1500, 20), (1500, 20))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build features matrices\n",
    "\n",
    "def build_features(split_ds):\n",
    "    Xs = []\n",
    "    y = []\n",
    "    for ex in split_ds:\n",
    "        x_struct, names = build_structured_features(ex)\n",
    "        if REPRESENTATION_MODE == \"structured\":\n",
    "            feats = x_struct\n",
    "        else:\n",
    "            # simple text embedding via hashing averaging (no heavy models)\n",
    "            gt_txt = render_structure_string(ex[\"ground_truth\"][\"cells\"], include_text=True)\n",
    "            pr_txt = render_structure_string(ex[\"generated\"][\"cells\"], include_text=True)\n",
    "            # very light bag-of-ngrams via hashing to fixed dims\n",
    "            dims = 512\n",
    "            vec = np.zeros(dims, dtype=np.float32)\n",
    "            for s in [gt_txt, pr_txt]:\n",
    "                for tok in s.split():\n",
    "                    h = hash(tok) % dims\n",
    "                    vec[h] += 1.0\n",
    "            if REPRESENTATION_MODE == \"embed\":\n",
    "                feats = vec\n",
    "            else:  # hybrid\n",
    "                feats = np.concatenate([x_struct, vec], axis=0)\n",
    "        Xs.append(feats)\n",
    "        y.append(float(ex[\"similarity_score\"]))\n",
    "    X = np.stack(Xs)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = build_features(train_ds)\n",
    "X_val, y_val = build_features(val_ds)\n",
    "X_test, y_test = build_features(test_ds)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "\n",
    "class NpDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = torch.from_numpy(X).float()\n",
    "        self.y = torch.from_numpy(y).float()\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_ds_np = NpDataset(X_train, y_train)\n",
    "val_ds_np = NpDataset(X_val, y_val)\n",
    "test_ds_np = NpDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_ds_np, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_ds_np, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_ds_np, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden: List[int], dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = in_dim\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(d, h), nn.ReLU(), nn.Dropout(dropout), nn.LayerNorm(h)]\n",
    "            d = h\n",
    "        layers += [nn.Linear(d, 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "model = MLP(X_train.shape[1], HIDDEN_SIZES, DROPOUT).to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "crit = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - train_loss=0.0571 val_RMSE=0.0606\n",
      "Epoch 2/10 - train_loss=0.0079 val_RMSE=0.0557\n",
      "Epoch 3/10 - train_loss=0.0050 val_RMSE=0.0501\n",
      "Epoch 4/10 - train_loss=0.0038 val_RMSE=0.0520\n",
      "Epoch 5/10 - train_loss=0.0030 val_RMSE=0.0435\n",
      "Epoch 6/10 - train_loss=0.0026 val_RMSE=0.0387\n",
      "Epoch 7/10 - train_loss=0.0022 val_RMSE=0.0397\n",
      "Epoch 8/10 - train_loss=0.0020 val_RMSE=0.0436\n",
      "Epoch 9/10 - train_loss=0.0019 val_RMSE=0.0346\n",
      "Epoch 10/10 - train_loss=0.0017 val_RMSE=0.0387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop with early stopping\n",
    "\n",
    "best_val = float(\"inf\")\n",
    "pat = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    tr_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = crit(pred, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        tr_loss += loss.item() * xb.size(0)\n",
    "    tr_loss /= len(train_loader.dataset)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = []\n",
    "        val_targets = []\n",
    "        for xb, yb in val_loader:\n",
    "            xb = xb.to(device)\n",
    "            yb = yb.to(device)\n",
    "            pred = model(xb)\n",
    "            val_preds.append(pred.cpu().numpy())\n",
    "            val_targets.append(yb.cpu().numpy())\n",
    "    val_preds = np.concatenate(val_preds)\n",
    "    val_targets = np.concatenate(val_targets)\n",
    "    val_rmse = math.sqrt(mean_squared_error(val_targets, val_preds))\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - train_loss={tr_loss:.4f} val_RMSE={val_rmse:.4f}\")\n",
    "\n",
    "    if val_rmse < best_val - 1e-4:\n",
    "        best_val = val_rmse\n",
    "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        pat = 0\n",
    "    else:\n",
    "        pat += 1\n",
    "        if pat >= EARLY_STOP_PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# Load best\n",
    "model.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RMSE': 0.03804979535151119, 'MAE': 0.029006972908973694, 'R2': 0.8095035552978516}\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    test_targets = []\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        pred = model(xb)\n",
    "        test_preds.append(pred.cpu().numpy())\n",
    "        test_targets.append(yb.cpu().numpy())\n",
    "\n",
    "test_preds = np.concatenate(test_preds)\n",
    "test_targets = np.concatenate(test_targets)\n",
    "\n",
    "rmse = math.sqrt(mean_squared_error(test_targets, test_preds))\n",
    "mae = mean_absolute_error(test_targets, test_preds)\n",
    "r2 = r2_score(test_targets, test_preds)\n",
    "print({\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: experiments/run_mlp_1761893738\n"
     ]
    }
   ],
   "source": [
    "# Save artifacts\n",
    "import os, time, joblib\n",
    "from pathlib import Path\n",
    "\n",
    "run_dir = Path(\"experiments\") / f\"run_mlp_{int(time.time())}\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(scaler, run_dir / \"scaler.joblib\")\n",
    "torch.save(model.state_dict(), run_dir / \"model.pt\")\n",
    "with open(run_dir / \"metrics.json\", \"w\") as f:\n",
    "    json.dump({\"RMSE\": float(rmse), \"MAE\": float(mae), \"R2\": float(r2)}, f)\n",
    "with open(run_dir / \"config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"REPRESENTATION_MODE\": REPRESENTATION_MODE,\n",
    "        \"HIDDEN_SIZES\": HIDDEN_SIZES,\n",
    "        \"DROPOUT\": DROPOUT,\n",
    "        \"LEARNING_RATE\": LEARNING_RATE,\n",
    "        \"WEIGHT_DECAY\": WEIGHT_DECAY,\n",
    "        \"BATCH_SIZE\": BATCH_SIZE,\n",
    "        \"EPOCHS\": EPOCHS,\n",
    "        \"SEED\": SEED\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved to:\", run_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
