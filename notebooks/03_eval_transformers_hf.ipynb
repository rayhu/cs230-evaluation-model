{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Structure Evaluation â€“ Hugging Face Transformers\n",
    "\n",
    "Fine-tune a transformer encoder for regression to predict table structure similarity.\n",
    "\n",
    "- Dataset: `rayhu/table-extraction-evaluation` ([Hugging Face dataset](https://huggingface.co/datasets/rayhu/table-extraction-evaluation))\n",
    "- Model: DistilBERT (configurable) + pooling + regression head\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"HF_DATASETS_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "SEED = 42\n",
    "VAL_FRAC = 0.5\n",
    "LIMIT = None\n",
    "MODEL_NAME = \"distilbert-base-uncased\"\n",
    "MAX_LENGTH = 512\n",
    "LR = 2e-5\n",
    "EPOCHS = 3\n",
    "TRAIN_BATCH = 16\n",
    "EVAL_BATCH = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import (AutoTokenizer, AutoModel, AutoConfig, Trainer, TrainingArguments,\n",
    "                          DataCollatorWithPadding, AutoModelForSequenceClassification)\n",
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
    "print(\"Device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 11971 val: 1500 test: 1500\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and split\n",
    "\n",
    "ds = load_dataset(\"rayhu/table-extraction-evaluation\")\n",
    "train_ds = ds[\"train\"]\n",
    "split = ds[\"test\"].train_test_split(test_size=1-VAL_FRAC, seed=SEED)\n",
    "val_ds = split[\"train\"]\n",
    "test_ds = split[\"test\"]\n",
    "\n",
    "if LIMIT is not None:\n",
    "    train_ds = train_ds.select(range(min(LIMIT, len(train_ds))))\n",
    "    val_ds = val_ds.select(range(min(max(1, LIMIT//5), len(val_ds))))\n",
    "    test_ds = test_ds.select(range(min(max(1, LIMIT//5), len(test_ds))))\n",
    "\n",
    "print(\"train:\", len(train_ds), \"val:\", len(val_ds), \"test:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e748998b03874d3f800e73cf7bd750ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11971 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19041a1b547241e286d2b69fee995852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14feffc5fd1241a09774d98573a235b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# String rendering for structure\n",
    "\n",
    "def render_structure_string(cells, include_text=True):\n",
    "    parts = []\n",
    "    for c in cells:\n",
    "        pos = f\"r{c.get('start_row',0)}c{c.get('start_col',0)}-r{c.get('end_row',0)}c{c.get('end_col',0)}\"\n",
    "        if include_text:\n",
    "            content = \" \".join(c.get(\"content\", [])[:5])\n",
    "            parts.append(f\"{pos}:{content}\")\n",
    "        else:\n",
    "            parts.append(pos)\n",
    "    return \" | \".join(parts[:512])\n",
    "\n",
    "\n",
    "def to_text(example):\n",
    "    gt = render_structure_string(example[\"ground_truth\"][\"cells\"], True)\n",
    "    pr = render_structure_string(example[\"generated\"][\"cells\"], True)\n",
    "    return {\"text\": gt + \" [SEP] \" + pr, \"label\": float(example[\"similarity_score\"]) }\n",
    "\n",
    "train_txt = train_ds.map(to_text)\n",
    "val_txt = val_ds.map(to_text)\n",
    "test_txt = test_ds.map(to_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77eed343c0b4401c81adbc6a80d2ea6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a3f9bf49c84cb6b7789ef3e9498221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a12ec5dd2d444b88e610d444d124f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc337d7b628d47bca72b8500d34692ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74757bf8e2b14880a9c6a0901bfb3d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/11971 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b68923bf82341f59ae5679686e23dc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cec41345c04246beaee89d980f4496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3daad04101d44afbecd3c6298e342a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-10-31T07:00:39.685624Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31mPython exception updating progress:, error: PyErr { type: <class 'LookupError'>, value: LookupError(<ContextVar name='shell_parent' at 0x10b1905e0>), traceback: Some(<traceback object at 0x31aa81380>) }, \u001b[1;31mcaller\u001b[0m\u001b[31m: \"src/progress_update.rs:313\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "def tok_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], truncation=True, max_length=MAX_LENGTH)\n",
    "\n",
    "train_tok = train_txt.map(tok_fn, batched=True, remove_columns=train_txt.column_names)\n",
    "val_tok = val_txt.map(tok_fn, batched=True, remove_columns=val_txt.column_names)\n",
    "test_tok = test_txt.map(tok_fn, batched=True, remove_columns=test_txt.column_names)\n",
    "\n",
    "# Regression head via sequence classification with 1 label\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=1, problem_type=\"regression\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "metric_mae = evaluate.load(\"mae\")\n",
    "metric_rmse = evaluate.load(\"rmse\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    preds, labels = eval_pred\n",
    "    preds = preds.reshape(-1)\n",
    "    labels = labels.reshape(-1)\n",
    "    return {\n",
    "        \"mae\": metric_mae.compute(predictions=preds, references=labels)[\"mae\"],\n",
    "        \"rmse\": metric_rmse.compute(predictions=preds, references=labels)[\"rmse\"],\n",
    "    }\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\"experiments/hf_transformers\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCH,\n",
    "    per_device_eval_batch_size=EVAL_BATCH,\n",
    "    learning_rate=LR,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rmse\",\n",
    "    greater_is_better=False,\n",
    "    seed=SEED,\n",
    "    fp16=torch.cuda.is_available(),\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=val_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and save\n",
    "metrics = trainer.evaluate(test_tok)\n",
    "print(metrics)\n",
    "\n",
    "trainer.save_model(\"experiments/hf_transformers/best_model\")\n",
    "tokenizer.save_pretrained(\"experiments/hf_transformers/best_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
