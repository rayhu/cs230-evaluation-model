{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Structure Evaluation â€“ Sentence-Transformers\n",
    "\n",
    "Use sentence embeddings for ground-truth and generated tables, then train regressors to predict similarity.\n",
    "\n",
    "- Dataset: `rayhu/table-extraction-evaluation` ([Hugging Face dataset](https://huggingface.co/datasets/rayhu/table-extraction-evaluation))\n",
    "- Embedding: `sentence-transformers` models (configurable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "os.environ[\"HF_DATASETS_DISABLE_PROGRESS_BARS\"] = \"1\" \n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x120ca4a30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Config\n",
    "SEED = 42\n",
    "VAL_FRAC = 0.5\n",
    "LIMIT = None\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "COMBINE = \"concat-diff-prod\"  # \"concat\" | \"concat-diff-prod\"\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 11971 val: 1500 test: 1500\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and split\n",
    "\n",
    "ds = load_dataset(\"rayhu/table-extraction-evaluation\")\n",
    "train_ds = ds[\"train\"]\n",
    "split = ds[\"test\"].train_test_split(test_size=1-VAL_FRAC, seed=SEED)\n",
    "val_ds = split[\"train\"]\n",
    "test_ds = split[\"test\"]\n",
    "\n",
    "if LIMIT is not None:\n",
    "    train_ds = train_ds.select(range(min(LIMIT, len(train_ds))))\n",
    "    val_ds = val_ds.select(range(min(max(1, LIMIT//5), len(val_ds))))\n",
    "    test_ds = test_ds.select(range(min(max(1, LIMIT//5), len(test_ds))))\n",
    "\n",
    "print(\"train:\", len(train_ds), \"val:\", len(val_ds), \"test:\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text rendering\n",
    "\n",
    "def render_structure_string(cells, include_text=True):\n",
    "    parts = []\n",
    "    for c in cells:\n",
    "        pos = f\"r{c.get('start_row',0)}c{c.get('start_col',0)}-r{c.get('end_row',0)}c{c.get('end_col',0)}\"\n",
    "        if include_text:\n",
    "            content = \" \".join(c.get(\"content\", [])[:5])\n",
    "            parts.append(f\"{pos}:{content}\")\n",
    "        else:\n",
    "            parts.append(pos)\n",
    "    return \" | \".join(parts[:512])\n",
    "\n",
    "\n",
    "def to_pair_text(example):\n",
    "    gt = render_structure_string(example[\"ground_truth\"][\"cells\"], True)\n",
    "    pr = render_structure_string(example[\"generated\"][\"cells\"], True)\n",
    "    return gt, pr, float(example[\"similarity_score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6b71b2d8c94256a56a0acbfbdfcaac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692f981f34d04708b4bcefc33a32e473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76d0e5a493384ceb9f2761d242f9e08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ff357a56ee41e4b076c74750a71578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2459c412d27435baf4e9fd195073b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38227ba24ae44031ab732c0001f33332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \u001b[2m2025-10-31T06:59:25.000920Z\u001b[0m \u001b[31mERROR\u001b[0m  \u001b[31mPython exception updating progress:, error: PyErr { type: <class 'LookupError'>, value: LookupError(<ContextVar name='shell_parent' at 0x1077004a0>), traceback: Some(<traceback object at 0x157493700>) }, \u001b[1;31mcaller\u001b[0m\u001b[31m: \"src/progress_update.rs:313\"\u001b[0m\n",
      "    \u001b[2;3mat\u001b[0m /Users/runner/work/xet-core/xet-core/error_printer/src/lib.rs:28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode with Sentence-Transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import math\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "\n",
    "def build_embeddings(split_ds):\n",
    "    texts_gt = []\n",
    "    texts_pr = []\n",
    "    ys = []\n",
    "    for ex in split_ds:\n",
    "        gt, pr, y = to_pair_text(ex)\n",
    "        texts_gt.append(gt)\n",
    "        texts_pr.append(pr)\n",
    "        ys.append(y)\n",
    "    emb_gt = model.encode(texts_gt, batch_size=64, show_progress_bar=True, convert_to_numpy=True)\n",
    "    emb_pr = model.encode(texts_pr, batch_size=64, show_progress_bar=True, convert_to_numpy=True)\n",
    "    if COMBINE == \"concat\":\n",
    "        X = np.concatenate([emb_gt, emb_pr], axis=1)\n",
    "    else:\n",
    "        X = np.concatenate([emb_gt, emb_pr, np.abs(emb_gt - emb_pr), emb_gt * emb_pr], axis=1)\n",
    "    y = np.array(ys, dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = build_embeddings(train_ds)\n",
    "X_val, y_val = build_embeddings(val_ds)\n",
    "X_test, y_test = build_embeddings(test_ds)\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train regressors (Ridge baseline)\n",
    "reg = Ridge(alpha=1.0)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "val_pred = reg.predict(X_val)\n",
    "val_rmse = math.sqrt(mean_squared_error(y_val, val_pred))\n",
    "val_mae = mean_absolute_error(y_val, val_pred)\n",
    "print({\"val_RMSE\": val_rmse, \"val_MAE\": val_mae})\n",
    "\n",
    "test_pred = reg.predict(X_test)\n",
    "rmse = math.sqrt(mean_squared_error(y_test, test_pred))\n",
    "mae = mean_absolute_error(y_test, test_pred)\n",
    "r2 = r2_score(y_test, test_pred)\n",
    "print({\"RMSE\": rmse, \"MAE\": mae, \"R2\": r2})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "import os, time, joblib\n",
    "from pathlib import Path\n",
    "\n",
    "run_dir = Path(\"experiments\") / f\"run_st_{int(time.time())}\"\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "joblib.dump(reg, run_dir / \"regressor.joblib\")\n",
    "with open(run_dir / \"metrics.json\", \"w\") as f:\n",
    "    json.dump({\"RMSE\": float(rmse), \"MAE\": float(mae), \"R2\": float(r2)}, f)\n",
    "with open(run_dir / \"config.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"MODEL_NAME\": MODEL_NAME,\n",
    "        \"COMBINE\": COMBINE,\n",
    "        \"SEED\": SEED\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Saved to:\", run_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
